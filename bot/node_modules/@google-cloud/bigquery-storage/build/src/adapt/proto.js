"use strict";
// Copyright 2023 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
Object.defineProperty(exports, "__esModule", { value: true });
exports.normalizeDescriptor = exports.convertStorageSchemaToProto3Descriptor = exports.convertStorageSchemaToProto2Descriptor = void 0;
const protos = require("../../protos/protos");
const proto_mappings_1 = require("./proto_mappings");
const schema_mappings_1 = require("./schema_mappings");
const TableFieldSchema = protos.google.cloud.bigquery.storage.v1.TableFieldSchema;
const DescriptorProto = protos.google.protobuf.DescriptorProto;
const FieldDescriptorProto = protos.google.protobuf.FieldDescriptorProto;
const FileDescriptorProto = protos.google.protobuf.FileDescriptorProto;
const FileDescriptorSet = protos.google.protobuf.FileDescriptorSet;
const packedTypes = [
    FieldDescriptorProto.Type.TYPE_INT32,
    FieldDescriptorProto.Type.TYPE_INT64,
    FieldDescriptorProto.Type.TYPE_UINT32,
    FieldDescriptorProto.Type.TYPE_UINT64,
    FieldDescriptorProto.Type.TYPE_SINT32,
    FieldDescriptorProto.Type.TYPE_SINT64,
    FieldDescriptorProto.Type.TYPE_FIXED32,
    FieldDescriptorProto.Type.TYPE_FIXED64,
    FieldDescriptorProto.Type.TYPE_SFIXED32,
    FieldDescriptorProto.Type.TYPE_SFIXED64,
    FieldDescriptorProto.Type.TYPE_FLOAT,
    FieldDescriptorProto.Type.TYPE_DOUBLE,
    FieldDescriptorProto.Type.TYPE_BOOL,
    FieldDescriptorProto.Type.TYPE_ENUM,
];
/** Builds a DescriptorProto for a given table schema using proto2 syntax.
 * @param schema - a BigQuery Storage TableSchema.
 * @param scope - scope to namespace protobuf structs.
 * @returns DescriptorProto
 */
function convertStorageSchemaToProto2Descriptor(schema, scope) {
    const fds = convertStorageSchemaToFileDescriptorInternal(schema, scope, false);
    return normalizeDescriptorSet(fds);
}
exports.convertStorageSchemaToProto2Descriptor = convertStorageSchemaToProto2Descriptor;
/** Builds a DescriptorProto for a given table schema using proto3 syntax.
 * @param schema - a Bigquery TableSchema.
 * @param scope - scope to namespace protobuf structs.
 * @returns DescriptorProto
 */
function convertStorageSchemaToProto3Descriptor(schema, scope) {
    const fds = convertStorageSchemaToFileDescriptorInternal(schema, scope, true);
    return normalizeDescriptorSet(fds);
}
exports.convertStorageSchemaToProto3Descriptor = convertStorageSchemaToProto3Descriptor;
function convertStorageSchemaToFileDescriptorInternal(schema, scope, useProto3) {
    var _a, _b, _c;
    let fNumber = 0;
    const fields = [];
    const deps = new Map();
    for (const field of (_a = schema.fields) !== null && _a !== void 0 ? _a : []) {
        fNumber += 1;
        const currentScope = `${scope}_${field.name}`;
        const normalizedType = (0, schema_mappings_1.normalizeFieldType)(field);
        if (normalizedType === TableFieldSchema.Type.STRUCT ||
            normalizedType === TableFieldSchema.Type.RANGE) {
            let subSchema = {};
            switch (normalizedType) {
                case TableFieldSchema.Type.STRUCT:
                    subSchema = {
                        fields: field.fields,
                    };
                    break;
                case TableFieldSchema.Type.RANGE:
                    subSchema = {
                        fields: [
                            {
                                name: 'start',
                                type: (_b = field.rangeElementType) === null || _b === void 0 ? void 0 : _b.type,
                                mode: 'NULLABLE',
                            },
                            {
                                name: 'end',
                                type: (_c = field.rangeElementType) === null || _c === void 0 ? void 0 : _c.type,
                                mode: 'NULLABLE',
                            },
                        ],
                    };
            }
            const fd = convertStorageSchemaToFileDescriptorInternal(subSchema, currentScope, useProto3);
            for (const f of fd.file) {
                if (f.name) {
                    deps.set(f.name, f);
                }
            }
            const fdp = convertTableFieldSchemaToFieldDescriptorProto(field, fNumber, currentScope, useProto3);
            fields.push(fdp);
        }
        else {
            const fdp = convertTableFieldSchemaToFieldDescriptorProto(field, fNumber, currentScope, useProto3);
            fields.push(fdp);
        }
    }
    const dp = new DescriptorProto({
        name: scope,
        field: fields,
    });
    const depsNames = Array.from(deps.keys());
    const syntax = useProto3 ? 'proto3' : 'proto2';
    const fdp = new FileDescriptorProto({
        messageType: [dp],
        name: `${scope}.proto`,
        syntax,
        dependency: depsNames,
    });
    const fds = new FileDescriptorSet({
        file: [fdp, ...Array.from(deps.values())],
    });
    return fds;
}
function normalizeDescriptorSet(fds) {
    let dp = null;
    let fdpName;
    if (fds.file.length > 0) {
        // search root descriptor
        const fdp = fds.file[0];
        fdpName = fdp.name;
        if (fdp.messageType && fdp.messageType.length > 0) {
            dp = new DescriptorProto(fdp.messageType[0]);
        }
    }
    if (!dp) {
        throw Error('root descriptor not found');
    }
    for (const fdp of fds.file) {
        if (fdp.name === fdpName) {
            continue;
        }
        if (!dp.nestedType) {
            dp.nestedType = [];
        }
        if (!fdp.messageType) {
            continue;
        }
        for (const nestedDP of fdp.messageType) {
            dp.nestedType.push(normalizeDescriptor(new DescriptorProto(nestedDP)));
        }
    }
    return normalizeDescriptor(dp);
}
/**
 * Builds a self-contained DescriptorProto suitable for communicating schema
 * information with the BigQuery Storage write API. It's primarily used for cases where users are
 * interested in sending data using a predefined protocol buffer message.
 * @param dp - DescriptorProto to be bundled.
 * @return DescriptorProto
 */
function normalizeDescriptor(dp) {
    dp.name = normalizeName(dp.name);
    for (const f of dp.field) {
        if (!f.label) {
            f.label =
                protos.google.protobuf.FieldDescriptorProto.Label.LABEL_OPTIONAL;
        }
        if (f.proto3Optional) {
            f.proto3Optional = null;
        }
        if (f.oneofIndex) {
            f.oneofIndex = null;
        }
        if (f.options) {
            f.options.packed = shouldPackType(f.type, f.label, false);
        }
    }
    const normalizedNestedTypes = [];
    for (const nestedDP of dp.nestedType) {
        normalizedNestedTypes.push(normalizeDescriptor(new DescriptorProto(nestedDP)));
    }
    dp.nestedType = normalizedNestedTypes;
    return dp;
}
exports.normalizeDescriptor = normalizeDescriptor;
function normalizeName(name) {
    return name.replace(/\./, '_');
}
function convertTableFieldSchemaToFieldDescriptorProto(field, fNumber, scope, useProto3) {
    const name = field.name;
    const type = (0, schema_mappings_1.normalizeFieldType)(field);
    if (!type) {
        throw Error(`table field ${name} missing type`);
    }
    const label = (0, proto_mappings_1.convertModeToLabel)(field.mode, useProto3);
    let fdp;
    if (type === TableFieldSchema.Type.STRUCT ||
        type === TableFieldSchema.Type.RANGE) {
        fdp = new FieldDescriptorProto({
            name: name,
            number: fNumber,
            type: FieldDescriptorProto.Type.TYPE_MESSAGE,
            typeName: scope,
            label: label,
        });
    }
    else {
        const pType = proto_mappings_1.bqTypeToFieldTypeMap[type];
        if (pType === null) {
            throw Error(`table field type ${type} not supported`);
        }
        fdp = new FieldDescriptorProto({
            name: name,
            number: fNumber,
            type: pType,
            label: label,
            options: {
                packed: shouldPackType(pType, label, useProto3),
            },
            proto3Optional: isProto3Optional(label, useProto3),
        });
    }
    return fdp;
}
function shouldPackType(t, label, useProto3) {
    if (useProto3) {
        return false;
    }
    if (label !== FieldDescriptorProto.Label.LABEL_REPEATED) {
        return undefined;
    }
    return packedTypes.includes(t);
}
function isProto3Optional(label, useProto3) {
    if (!useProto3) {
        return undefined;
    }
    return label === FieldDescriptorProto.Label.LABEL_OPTIONAL;
}
//# sourceMappingURL=proto.js.map