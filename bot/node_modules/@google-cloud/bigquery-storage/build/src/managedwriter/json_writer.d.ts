import * as protos from '../../protos/protos';
import { PendingWrite } from './pending_write';
import { WriterOptions } from './writer';
type MissingValueInterpretation = protos.google.cloud.bigquery.storage.v1.AppendRowsRequest['defaultMissingValueInterpretation'];
type MissingValueInterpretationMap = {
    [column: string]: MissingValueInterpretation;
};
type IInt64Value = protos.google.protobuf.IInt64Value;
type IDescriptorProto = protos.google.protobuf.IDescriptorProto;
export type JSONPrimitive = string | number | bigint | boolean | Date | null;
export type JSONValue = JSONPrimitive | JSONObject | JSONArray;
export type JSONObject = {
    [member: string]: JSONValue;
};
export type JSONArray = Array<JSONValue>;
export type JSONList = Array<JSONObject>;
/**
 * A StreamWriter that can write JSON data to BigQuery tables. The JSONWriter is
 * built on top of a Writer, and it simply converts all JSON data to protobuf messages then
 * calls Writer's appendRows() method to write to BigQuery tables. It maintains all Writer
 * functions, but also provides an additional feature: schema update support, where if the BigQuery
 * table schema is updated, users will be able to ingest data on the new schema after some time (in
 * order of minutes).
 *
 * @class
 * @extends managedwriter.Writer
 * @memberof managedwriter
 * @see managedwriter.Writer
 */
export declare class JSONWriter {
    private _writer;
    private _encoder;
    private _schemaListener;
    /**
     * Creates a new JSONWriter instance.
     *
     * @param {WriterOptions} params - The parameters for the JSONWriter.
     *   See WriterOptions docs for more information.
     */
    constructor(params: WriterOptions);
    private onSchemaUpdated;
    /**
     * Update the proto descriptor for the Writer.
     * Internally a reconnection event is gonna happen to apply
     * the new proto descriptor.
     *
     * @param {IDescriptorProto} protoDescriptor - The proto descriptor.
     */
    setProtoDescriptor(protoDescriptor: IDescriptorProto): void;
    /**
     * Update how missing values are interpreted for the given stream.
     *
     * @param {MissingValueInterpretation} defaultMissingValueInterpretation
     */
    setDefaultMissingValueInterpretation(defaultMissingValueInterpretation: MissingValueInterpretation): void;
    /**
     * Update how missing values are interpreted for individual columns.
     *
     * @param {MissingValueInterpretationMap} missingValueInterpretations
     */
    setMissingValueInterpretations(missingValueInterpretations: MissingValueInterpretationMap): void;
    /**
     * Writes a JSONList that contains objects to be written to the BigQuery table by first converting
     * the JSON data to protobuf messages, then using Writer's appendRows() to write the data at current end
     * of stream. If there is a schema update, the current Writer is closed and reopened with the updated schema.
     *
     * @param {JSONList} rows - The list of JSON rows.
     * @param {number|Long|string|null} offsetValue? - The offset value.
     * @returns {managedwriter.PendingWrite} The pending write.
     */
    appendRows(rows: JSONList, offsetValue?: IInt64Value['value']): PendingWrite;
    close(): void;
}
export {};
