import type * as gax from 'google-gax';
import type { Callback, CallOptions, Descriptors, ClientOptions } from 'google-gax';
import * as protos from '../../protos/protos';
/**
 *  BigQuery Write API.
 *
 *  The Write API can be used to write data to BigQuery.
 *
 *  For supplementary information about the Write API, see:
 *  https://cloud.google.com/bigquery/docs/write-api
 * @class
 * @memberof v1
 */
export declare class BigQueryWriteClient {
    private _terminated;
    private _opts;
    private _providedCustomServicePath;
    private _gaxModule;
    private _gaxGrpc;
    private _protos;
    private _defaults;
    private _universeDomain;
    private _servicePath;
    auth: gax.GoogleAuth;
    descriptors: Descriptors;
    warn: (code: string, message: string, warnType?: string) => void;
    innerApiCalls: {
        [name: string]: Function;
    };
    pathTemplates: {
        [name: string]: gax.PathTemplate;
    };
    bigQueryWriteStub?: Promise<{
        [name: string]: Function;
    }>;
    /**
     * Construct an instance of BigQueryWriteClient.
     *
     * @param {object} [options] - The configuration object.
     * The options accepted by the constructor are described in detail
     * in [this document](https://github.com/googleapis/gax-nodejs/blob/main/client-libraries.md#creating-the-client-instance).
     * The common options are:
     * @param {object} [options.credentials] - Credentials object.
     * @param {string} [options.credentials.client_email]
     * @param {string} [options.credentials.private_key]
     * @param {string} [options.email] - Account email address. Required when
     *     using a .pem or .p12 keyFilename.
     * @param {string} [options.keyFilename] - Full path to the a .json, .pem, or
     *     .p12 key downloaded from the Google Developers Console. If you provide
     *     a path to a JSON file, the projectId option below is not necessary.
     *     NOTE: .pem and .p12 require you to specify options.email as well.
     * @param {number} [options.port] - The port on which to connect to
     *     the remote host.
     * @param {string} [options.projectId] - The project ID from the Google
     *     Developer's Console, e.g. 'grape-spaceship-123'. We will also check
     *     the environment variable GCLOUD_PROJECT for your project ID. If your
     *     app is running in an environment which supports
     *     {@link https://developers.google.com/identity/protocols/application-default-credentials Application Default Credentials},
     *     your project ID will be detected automatically.
     * @param {string} [options.apiEndpoint] - The domain name of the
     *     API remote host.
     * @param {gax.ClientConfig} [options.clientConfig] - Client configuration override.
     *     Follows the structure of {@link gapicConfig}.
     * @param {boolean} [options.fallback] - Use HTTP/1.1 REST mode.
     *     For more information, please check the
     *     {@link https://github.com/googleapis/gax-nodejs/blob/main/client-libraries.md#http11-rest-api-mode documentation}.
     * @param {gax} [gaxInstance]: loaded instance of `google-gax`. Useful if you
     *     need to avoid loading the default gRPC version and want to use the fallback
     *     HTTP implementation. Load only fallback version and pass it to the constructor:
     *     ```
     *     const gax = require('google-gax/build/src/fallback'); // avoids loading google-gax with gRPC
     *     const client = new BigQueryWriteClient({fallback: true}, gax);
     *     ```
     */
    constructor(opts?: ClientOptions, gaxInstance?: typeof gax | typeof gax.fallback);
    /**
     * Initialize the client.
     * Performs asynchronous operations (such as authentication) and prepares the client.
     * This function will be called automatically when any class method is called for the
     * first time, but if you need to initialize it before calling an actual method,
     * feel free to call initialize() directly.
     *
     * You can await on this method if you want to make sure the client is initialized.
     *
     * @returns {Promise} A promise that resolves to an authenticated service stub.
     */
    initialize(): Promise<{
        [name: string]: Function;
    }>;
    /**
     * The DNS address for this API service.
     * @deprecated Use the apiEndpoint method of the client instance.
     * @returns {string} The DNS address for this service.
     */
    static get servicePath(): string;
    /**
     * The DNS address for this API service - same as servicePath.
     * @deprecated Use the apiEndpoint method of the client instance.
     * @returns {string} The DNS address for this service.
     */
    static get apiEndpoint(): string;
    /**
     * The DNS address for this API service.
     * @returns {string} The DNS address for this service.
     */
    get apiEndpoint(): string;
    get universeDomain(): string;
    /**
     * The port for this API service.
     * @returns {number} The default port for this service.
     */
    static get port(): number;
    /**
     * The scopes needed to make gRPC calls for every method defined
     * in this service.
     * @returns {string[]} List of default scopes.
     */
    static get scopes(): string[];
    getProjectId(): Promise<string>;
    getProjectId(callback: Callback<string, undefined, undefined>): void;
    /**
     * Creates a write stream to the given table.
     * Additionally, every table has a special stream named '_default'
     * to which data can be written. This stream doesn't need to be created using
     * CreateWriteStream. It is a stream that can be used simultaneously by any
     * number of clients. Data written to this stream is considered committed as
     * soon as an acknowledgement is received.
     *
     * @param {Object} request
     *   The request object that will be sent.
     * @param {string} request.parent
     *   Required. Reference to the table to which the stream belongs, in the format
     *   of `projects/{project}/datasets/{dataset}/tables/{table}`.
     * @param {google.cloud.bigquery.storage.v1.WriteStream} request.writeStream
     *   Required. Stream to be created.
     * @param {object} [options]
     *   Call options. See {@link https://googleapis.dev/nodejs/google-gax/latest/interfaces/CallOptions.html|CallOptions} for more details.
     * @returns {Promise} - The promise which resolves to an array.
     *   The first element of the array is an object representing {@link protos.google.cloud.bigquery.storage.v1.WriteStream|WriteStream}.
     *   Please see the {@link https://github.com/googleapis/gax-nodejs/blob/master/client-libraries.md#regular-methods | documentation }
     *   for more details and examples.
     * @example <caption>include:samples/generated/v1/big_query_write.create_write_stream.js</caption>
     * region_tag:bigquerystorage_v1_generated_BigQueryWrite_CreateWriteStream_async
     */
    createWriteStream(request?: protos.google.cloud.bigquery.storage.v1.ICreateWriteStreamRequest, options?: CallOptions): Promise<[
        protos.google.cloud.bigquery.storage.v1.IWriteStream,
        (protos.google.cloud.bigquery.storage.v1.ICreateWriteStreamRequest | undefined),
        {} | undefined
    ]>;
    createWriteStream(request: protos.google.cloud.bigquery.storage.v1.ICreateWriteStreamRequest, options: CallOptions, callback: Callback<protos.google.cloud.bigquery.storage.v1.IWriteStream, protos.google.cloud.bigquery.storage.v1.ICreateWriteStreamRequest | null | undefined, {} | null | undefined>): void;
    createWriteStream(request: protos.google.cloud.bigquery.storage.v1.ICreateWriteStreamRequest, callback: Callback<protos.google.cloud.bigquery.storage.v1.IWriteStream, protos.google.cloud.bigquery.storage.v1.ICreateWriteStreamRequest | null | undefined, {} | null | undefined>): void;
    /**
     * Gets information about a write stream.
     *
     * @param {Object} request
     *   The request object that will be sent.
     * @param {string} request.name
     *   Required. Name of the stream to get, in the form of
     *   `projects/{project}/datasets/{dataset}/tables/{table}/streams/{stream}`.
     * @param {google.cloud.bigquery.storage.v1.WriteStreamView} request.view
     *   Indicates whether to get full or partial view of the WriteStream. If
     *   not set, view returned will be basic.
     * @param {object} [options]
     *   Call options. See {@link https://googleapis.dev/nodejs/google-gax/latest/interfaces/CallOptions.html|CallOptions} for more details.
     * @returns {Promise} - The promise which resolves to an array.
     *   The first element of the array is an object representing {@link protos.google.cloud.bigquery.storage.v1.WriteStream|WriteStream}.
     *   Please see the {@link https://github.com/googleapis/gax-nodejs/blob/master/client-libraries.md#regular-methods | documentation }
     *   for more details and examples.
     * @example <caption>include:samples/generated/v1/big_query_write.get_write_stream.js</caption>
     * region_tag:bigquerystorage_v1_generated_BigQueryWrite_GetWriteStream_async
     */
    getWriteStream(request?: protos.google.cloud.bigquery.storage.v1.IGetWriteStreamRequest, options?: CallOptions): Promise<[
        protos.google.cloud.bigquery.storage.v1.IWriteStream,
        (protos.google.cloud.bigquery.storage.v1.IGetWriteStreamRequest | undefined),
        {} | undefined
    ]>;
    getWriteStream(request: protos.google.cloud.bigquery.storage.v1.IGetWriteStreamRequest, options: CallOptions, callback: Callback<protos.google.cloud.bigquery.storage.v1.IWriteStream, protos.google.cloud.bigquery.storage.v1.IGetWriteStreamRequest | null | undefined, {} | null | undefined>): void;
    getWriteStream(request: protos.google.cloud.bigquery.storage.v1.IGetWriteStreamRequest, callback: Callback<protos.google.cloud.bigquery.storage.v1.IWriteStream, protos.google.cloud.bigquery.storage.v1.IGetWriteStreamRequest | null | undefined, {} | null | undefined>): void;
    /**
     * Finalize a write stream so that no new data can be appended to the
     * stream. Finalize is not supported on the '_default' stream.
     *
     * @param {Object} request
     *   The request object that will be sent.
     * @param {string} request.name
     *   Required. Name of the stream to finalize, in the form of
     *   `projects/{project}/datasets/{dataset}/tables/{table}/streams/{stream}`.
     * @param {object} [options]
     *   Call options. See {@link https://googleapis.dev/nodejs/google-gax/latest/interfaces/CallOptions.html|CallOptions} for more details.
     * @returns {Promise} - The promise which resolves to an array.
     *   The first element of the array is an object representing {@link protos.google.cloud.bigquery.storage.v1.FinalizeWriteStreamResponse|FinalizeWriteStreamResponse}.
     *   Please see the {@link https://github.com/googleapis/gax-nodejs/blob/master/client-libraries.md#regular-methods | documentation }
     *   for more details and examples.
     * @example <caption>include:samples/generated/v1/big_query_write.finalize_write_stream.js</caption>
     * region_tag:bigquerystorage_v1_generated_BigQueryWrite_FinalizeWriteStream_async
     */
    finalizeWriteStream(request?: protos.google.cloud.bigquery.storage.v1.IFinalizeWriteStreamRequest, options?: CallOptions): Promise<[
        protos.google.cloud.bigquery.storage.v1.IFinalizeWriteStreamResponse,
        (protos.google.cloud.bigquery.storage.v1.IFinalizeWriteStreamRequest | undefined),
        {} | undefined
    ]>;
    finalizeWriteStream(request: protos.google.cloud.bigquery.storage.v1.IFinalizeWriteStreamRequest, options: CallOptions, callback: Callback<protos.google.cloud.bigquery.storage.v1.IFinalizeWriteStreamResponse, protos.google.cloud.bigquery.storage.v1.IFinalizeWriteStreamRequest | null | undefined, {} | null | undefined>): void;
    finalizeWriteStream(request: protos.google.cloud.bigquery.storage.v1.IFinalizeWriteStreamRequest, callback: Callback<protos.google.cloud.bigquery.storage.v1.IFinalizeWriteStreamResponse, protos.google.cloud.bigquery.storage.v1.IFinalizeWriteStreamRequest | null | undefined, {} | null | undefined>): void;
    /**
     * Atomically commits a group of `PENDING` streams that belong to the same
     * `parent` table.
     *
     * Streams must be finalized before commit and cannot be committed multiple
     * times. Once a stream is committed, data in the stream becomes available
     * for read operations.
     *
     * @param {Object} request
     *   The request object that will be sent.
     * @param {string} request.parent
     *   Required. Parent table that all the streams should belong to, in the form
     *   of `projects/{project}/datasets/{dataset}/tables/{table}`.
     * @param {string[]} request.writeStreams
     *   Required. The group of streams that will be committed atomically.
     * @param {object} [options]
     *   Call options. See {@link https://googleapis.dev/nodejs/google-gax/latest/interfaces/CallOptions.html|CallOptions} for more details.
     * @returns {Promise} - The promise which resolves to an array.
     *   The first element of the array is an object representing {@link protos.google.cloud.bigquery.storage.v1.BatchCommitWriteStreamsResponse|BatchCommitWriteStreamsResponse}.
     *   Please see the {@link https://github.com/googleapis/gax-nodejs/blob/master/client-libraries.md#regular-methods | documentation }
     *   for more details and examples.
     * @example <caption>include:samples/generated/v1/big_query_write.batch_commit_write_streams.js</caption>
     * region_tag:bigquerystorage_v1_generated_BigQueryWrite_BatchCommitWriteStreams_async
     */
    batchCommitWriteStreams(request?: protos.google.cloud.bigquery.storage.v1.IBatchCommitWriteStreamsRequest, options?: CallOptions): Promise<[
        protos.google.cloud.bigquery.storage.v1.IBatchCommitWriteStreamsResponse,
        (protos.google.cloud.bigquery.storage.v1.IBatchCommitWriteStreamsRequest | undefined),
        {} | undefined
    ]>;
    batchCommitWriteStreams(request: protos.google.cloud.bigquery.storage.v1.IBatchCommitWriteStreamsRequest, options: CallOptions, callback: Callback<protos.google.cloud.bigquery.storage.v1.IBatchCommitWriteStreamsResponse, protos.google.cloud.bigquery.storage.v1.IBatchCommitWriteStreamsRequest | null | undefined, {} | null | undefined>): void;
    batchCommitWriteStreams(request: protos.google.cloud.bigquery.storage.v1.IBatchCommitWriteStreamsRequest, callback: Callback<protos.google.cloud.bigquery.storage.v1.IBatchCommitWriteStreamsResponse, protos.google.cloud.bigquery.storage.v1.IBatchCommitWriteStreamsRequest | null | undefined, {} | null | undefined>): void;
    /**
     * Flushes rows to a BUFFERED stream.
     *
     * If users are appending rows to BUFFERED stream, flush operation is
     * required in order for the rows to become available for reading. A
     * Flush operation flushes up to any previously flushed offset in a BUFFERED
     * stream, to the offset specified in the request.
     *
     * Flush is not supported on the _default stream, since it is not BUFFERED.
     *
     * @param {Object} request
     *   The request object that will be sent.
     * @param {string} request.writeStream
     *   Required. The stream that is the target of the flush operation.
     * @param {google.protobuf.Int64Value} request.offset
     *   Ending offset of the flush operation. Rows before this offset(including
     *   this offset) will be flushed.
     * @param {object} [options]
     *   Call options. See {@link https://googleapis.dev/nodejs/google-gax/latest/interfaces/CallOptions.html|CallOptions} for more details.
     * @returns {Promise} - The promise which resolves to an array.
     *   The first element of the array is an object representing {@link protos.google.cloud.bigquery.storage.v1.FlushRowsResponse|FlushRowsResponse}.
     *   Please see the {@link https://github.com/googleapis/gax-nodejs/blob/master/client-libraries.md#regular-methods | documentation }
     *   for more details and examples.
     * @example <caption>include:samples/generated/v1/big_query_write.flush_rows.js</caption>
     * region_tag:bigquerystorage_v1_generated_BigQueryWrite_FlushRows_async
     */
    flushRows(request?: protos.google.cloud.bigquery.storage.v1.IFlushRowsRequest, options?: CallOptions): Promise<[
        protos.google.cloud.bigquery.storage.v1.IFlushRowsResponse,
        protos.google.cloud.bigquery.storage.v1.IFlushRowsRequest | undefined,
        {} | undefined
    ]>;
    flushRows(request: protos.google.cloud.bigquery.storage.v1.IFlushRowsRequest, options: CallOptions, callback: Callback<protos.google.cloud.bigquery.storage.v1.IFlushRowsResponse, protos.google.cloud.bigquery.storage.v1.IFlushRowsRequest | null | undefined, {} | null | undefined>): void;
    flushRows(request: protos.google.cloud.bigquery.storage.v1.IFlushRowsRequest, callback: Callback<protos.google.cloud.bigquery.storage.v1.IFlushRowsResponse, protos.google.cloud.bigquery.storage.v1.IFlushRowsRequest | null | undefined, {} | null | undefined>): void;
    /**
     * Appends data to the given stream.
     *
     * If `offset` is specified, the `offset` is checked against the end of
     * stream. The server returns `OUT_OF_RANGE` in `AppendRowsResponse` if an
     * attempt is made to append to an offset beyond the current end of the stream
     * or `ALREADY_EXISTS` if user provides an `offset` that has already been
     * written to. User can retry with adjusted offset within the same RPC
     * connection. If `offset` is not specified, append happens at the end of the
     * stream.
     *
     * The response contains an optional offset at which the append
     * happened.  No offset information will be returned for appends to a
     * default stream.
     *
     * Responses are received in the same order in which requests are sent.
     * There will be one response for each successful inserted request.  Responses
     * may optionally embed error information if the originating AppendRequest was
     * not successfully processed.
     *
     * The specifics of when successfully appended data is made visible to the
     * table are governed by the type of stream:
     *
     * * For COMMITTED streams (which includes the default stream), data is
     * visible immediately upon successful append.
     *
     * * For BUFFERED streams, data is made visible via a subsequent `FlushRows`
     * rpc which advances a cursor to a newer offset in the stream.
     *
     * * For PENDING streams, data is not made visible until the stream itself is
     * finalized (via the `FinalizeWriteStream` rpc), and the stream is explicitly
     * committed via the `BatchCommitWriteStreams` rpc.
     *
     * @param {object} [options]
     *   Call options. See {@link https://googleapis.dev/nodejs/google-gax/latest/interfaces/CallOptions.html|CallOptions} for more details.
     * @returns {Stream}
     *   An object stream which is both readable and writable. It accepts objects
     *   representing {@link protos.google.cloud.bigquery.storage.v1.AppendRowsRequest|AppendRowsRequest} for write() method, and
     *   will emit objects representing {@link protos.google.cloud.bigquery.storage.v1.AppendRowsResponse|AppendRowsResponse} on 'data' event asynchronously.
     *   Please see the {@link https://github.com/googleapis/gax-nodejs/blob/master/client-libraries.md#bi-directional-streaming | documentation }
     *   for more details and examples.
     * @example <caption>include:samples/generated/v1/big_query_write.append_rows.js</caption>
     * region_tag:bigquerystorage_v1_generated_BigQueryWrite_AppendRows_async
     */
    appendRows(options?: CallOptions): gax.CancellableStream;
    /**
     * Return a fully-qualified project resource name string.
     *
     * @param {string} project
     * @returns {string} Resource name string.
     */
    projectPath(project: string): string;
    /**
     * Parse the project from Project resource.
     *
     * @param {string} projectName
     *   A fully-qualified path representing Project resource.
     * @returns {string} A string representing the project.
     */
    matchProjectFromProjectName(projectName: string): string | number;
    /**
     * Return a fully-qualified readSession resource name string.
     *
     * @param {string} project
     * @param {string} location
     * @param {string} session
     * @returns {string} Resource name string.
     */
    readSessionPath(project: string, location: string, session: string): string;
    /**
     * Parse the project from ReadSession resource.
     *
     * @param {string} readSessionName
     *   A fully-qualified path representing ReadSession resource.
     * @returns {string} A string representing the project.
     */
    matchProjectFromReadSessionName(readSessionName: string): string | number;
    /**
     * Parse the location from ReadSession resource.
     *
     * @param {string} readSessionName
     *   A fully-qualified path representing ReadSession resource.
     * @returns {string} A string representing the location.
     */
    matchLocationFromReadSessionName(readSessionName: string): string | number;
    /**
     * Parse the session from ReadSession resource.
     *
     * @param {string} readSessionName
     *   A fully-qualified path representing ReadSession resource.
     * @returns {string} A string representing the session.
     */
    matchSessionFromReadSessionName(readSessionName: string): string | number;
    /**
     * Return a fully-qualified readStream resource name string.
     *
     * @param {string} project
     * @param {string} location
     * @param {string} session
     * @param {string} stream
     * @returns {string} Resource name string.
     */
    readStreamPath(project: string, location: string, session: string, stream: string): string;
    /**
     * Parse the project from ReadStream resource.
     *
     * @param {string} readStreamName
     *   A fully-qualified path representing ReadStream resource.
     * @returns {string} A string representing the project.
     */
    matchProjectFromReadStreamName(readStreamName: string): string | number;
    /**
     * Parse the location from ReadStream resource.
     *
     * @param {string} readStreamName
     *   A fully-qualified path representing ReadStream resource.
     * @returns {string} A string representing the location.
     */
    matchLocationFromReadStreamName(readStreamName: string): string | number;
    /**
     * Parse the session from ReadStream resource.
     *
     * @param {string} readStreamName
     *   A fully-qualified path representing ReadStream resource.
     * @returns {string} A string representing the session.
     */
    matchSessionFromReadStreamName(readStreamName: string): string | number;
    /**
     * Parse the stream from ReadStream resource.
     *
     * @param {string} readStreamName
     *   A fully-qualified path representing ReadStream resource.
     * @returns {string} A string representing the stream.
     */
    matchStreamFromReadStreamName(readStreamName: string): string | number;
    /**
     * Return a fully-qualified table resource name string.
     *
     * @param {string} project
     * @param {string} dataset
     * @param {string} table
     * @returns {string} Resource name string.
     */
    tablePath(project: string, dataset: string, table: string): string;
    /**
     * Parse the project from Table resource.
     *
     * @param {string} tableName
     *   A fully-qualified path representing Table resource.
     * @returns {string} A string representing the project.
     */
    matchProjectFromTableName(tableName: string): string | number;
    /**
     * Parse the dataset from Table resource.
     *
     * @param {string} tableName
     *   A fully-qualified path representing Table resource.
     * @returns {string} A string representing the dataset.
     */
    matchDatasetFromTableName(tableName: string): string | number;
    /**
     * Parse the table from Table resource.
     *
     * @param {string} tableName
     *   A fully-qualified path representing Table resource.
     * @returns {string} A string representing the table.
     */
    matchTableFromTableName(tableName: string): string | number;
    /**
     * Return a fully-qualified writeStream resource name string.
     *
     * @param {string} project
     * @param {string} dataset
     * @param {string} table
     * @param {string} stream
     * @returns {string} Resource name string.
     */
    writeStreamPath(project: string, dataset: string, table: string, stream: string): string;
    /**
     * Parse the project from WriteStream resource.
     *
     * @param {string} writeStreamName
     *   A fully-qualified path representing WriteStream resource.
     * @returns {string} A string representing the project.
     */
    matchProjectFromWriteStreamName(writeStreamName: string): string | number;
    /**
     * Parse the dataset from WriteStream resource.
     *
     * @param {string} writeStreamName
     *   A fully-qualified path representing WriteStream resource.
     * @returns {string} A string representing the dataset.
     */
    matchDatasetFromWriteStreamName(writeStreamName: string): string | number;
    /**
     * Parse the table from WriteStream resource.
     *
     * @param {string} writeStreamName
     *   A fully-qualified path representing WriteStream resource.
     * @returns {string} A string representing the table.
     */
    matchTableFromWriteStreamName(writeStreamName: string): string | number;
    /**
     * Parse the stream from WriteStream resource.
     *
     * @param {string} writeStreamName
     *   A fully-qualified path representing WriteStream resource.
     * @returns {string} A string representing the stream.
     */
    matchStreamFromWriteStreamName(writeStreamName: string): string | number;
    /**
     * Terminate the gRPC channel and close the client.
     *
     * The client will no longer be usable and all future behavior is undefined.
     * @returns {Promise} A promise that resolves when the client is closed.
     */
    close(): Promise<void>;
}
